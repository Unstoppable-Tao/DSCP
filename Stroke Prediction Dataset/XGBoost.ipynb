{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b78e7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import optuna\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d855774",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('cleaned.csv',index_col=0)\n",
    "train_copy=df.drop(columns=['bmi','avg_glucose_level','age'])\n",
    "X = train_copy.drop('smoking_status', axis=1)\n",
    "y = train_copy['smoking_status']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c5cbdad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Accuracy: 0.5569\n",
      "Fold 2 Accuracy: 0.5416\n",
      "Fold 3 Accuracy: 0.5547\n",
      "Fold 4 Accuracy: 0.5387\n",
      "Fold 5 Accuracy: 0.5226\n",
      "\n",
      " avg_acc: 0.5429\n"
     ]
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "scores = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y)):\n",
    "    \n",
    "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    " \n",
    "    scaler = MinMaxScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "\n",
    "    model = xgb.XGBClassifier(\n",
    "        objective='binary:logistic',\n",
    "        max_depth=10,\n",
    "        learning_rate=0.1,\n",
    "        n_estimators=100,\n",
    "        eval_metric='logloss',\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    " \n",
    "    model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    \n",
    "    y_pred = model.predict(X_val_scaled)\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    print(f\"Fold {fold+1} Accuracy: {acc:.4f}\")\n",
    "    scores.append(acc)\n",
    "\n",
    "\n",
    "avg_acc = np.mean(scores)\n",
    "print(f\"\\n avg_acc: {avg_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05a5f7b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-22 16:26:32,286] A new study created in memory with name: no-name-f4d56623-9635-4be6-b200-8d6e763a70f5\n",
      "[I 2025-08-22 16:26:32,557] Trial 0 finished with value: 0.5747275010108319 and parameters: {'n_estimators': 300, 'max_depth': 3, 'learning_rate': 0.01596238623655878}. Best is trial 0 with value: 0.5747275010108319.\n",
      "[I 2025-08-22 16:26:32,986] Trial 1 finished with value: 0.5405703219765488 and parameters: {'n_estimators': 180, 'max_depth': 8, 'learning_rate': 0.27170267655794955}. Best is trial 0 with value: 0.5747275010108319.\n",
      "[I 2025-08-22 16:26:33,672] Trial 2 finished with value: 0.54319678236258 and parameters: {'n_estimators': 300, 'max_depth': 8, 'learning_rate': 0.05260210989093649}. Best is trial 0 with value: 0.5747275010108319.\n",
      "[I 2025-08-22 16:26:33,978] Trial 3 finished with value: 0.5534166116916005 and parameters: {'n_estimators': 200, 'max_depth': 4, 'learning_rate': 0.16335177525473613}. Best is trial 0 with value: 0.5747275010108319.\n",
      "[I 2025-08-22 16:26:34,458] Trial 4 finished with value: 0.5478661871422187 and parameters: {'n_estimators': 140, 'max_depth': 10, 'learning_rate': 0.056817920844988296}. Best is trial 0 with value: 0.5747275010108319.\n",
      "[I 2025-08-22 16:26:34,695] Trial 5 finished with value: 0.5572084016088187 and parameters: {'n_estimators': 160, 'max_depth': 6, 'learning_rate': 0.038328881453120876}. Best is trial 0 with value: 0.5747275010108319.\n",
      "[I 2025-08-22 16:26:35,098] Trial 6 finished with value: 0.5496201400268136 and parameters: {'n_estimators': 140, 'max_depth': 8, 'learning_rate': 0.0541723141749549}. Best is trial 0 with value: 0.5747275010108319.\n",
      "[I 2025-08-22 16:26:35,301] Trial 7 finished with value: 0.5592517716158414 and parameters: {'n_estimators': 140, 'max_depth': 6, 'learning_rate': 0.04276888938782828}. Best is trial 0 with value: 0.5747275010108319.\n",
      "[I 2025-08-22 16:26:35,484] Trial 8 finished with value: 0.575019897427167 and parameters: {'n_estimators': 140, 'max_depth': 3, 'learning_rate': 0.0164426493268974}. Best is trial 8 with value: 0.575019897427167.\n",
      "[I 2025-08-22 16:26:35,684] Trial 9 finished with value: 0.5572092528356494 and parameters: {'n_estimators': 120, 'max_depth': 6, 'learning_rate': 0.046610037291998405}. Best is trial 8 with value: 0.575019897427167.\n",
      "[I 2025-08-22 16:26:35,977] Trial 10 finished with value: 0.5723917345874743 and parameters: {'n_estimators': 240, 'max_depth': 4, 'learning_rate': 0.010007199787399872}. Best is trial 8 with value: 0.575019897427167.\n",
      "[I 2025-08-22 16:26:36,239] Trial 11 finished with value: 0.5744351045944969 and parameters: {'n_estimators': 300, 'max_depth': 3, 'learning_rate': 0.010688156946472975}. Best is trial 8 with value: 0.575019897427167.\n",
      "[I 2025-08-22 16:26:36,465] Trial 12 finished with value: 0.5744355302079122 and parameters: {'n_estimators': 240, 'max_depth': 3, 'learning_rate': 0.018991070970484657}. Best is trial 8 with value: 0.575019897427167.\n",
      "[I 2025-08-22 16:26:36,632] Trial 13 finished with value: 0.5709314549594603 and parameters: {'n_estimators': 100, 'max_depth': 4, 'learning_rate': 0.019839335237208006}. Best is trial 8 with value: 0.575019897427167.\n",
      "[I 2025-08-22 16:26:36,910] Trial 14 finished with value: 0.567721478581005 and parameters: {'n_estimators': 240, 'max_depth': 5, 'learning_rate': 0.02096205381759331}. Best is trial 8 with value: 0.575019897427167.\n",
      "[I 2025-08-22 16:26:37,180] Trial 15 finished with value: 0.5653852865442319 and parameters: {'n_estimators': 260, 'max_depth': 3, 'learning_rate': 0.09915023779977332}. Best is trial 8 with value: 0.575019897427167.\n",
      "[I 2025-08-22 16:26:37,426] Trial 16 finished with value: 0.5764763465344428 and parameters: {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.014777234896168582}. Best is trial 16 with value: 0.5764763465344428.\n",
      "[I 2025-08-22 16:26:37,775] Trial 17 finished with value: 0.566843438105169 and parameters: {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.029238657384501147}. Best is trial 16 with value: 0.5764763465344428.\n",
      "[I 2025-08-22 16:26:38,093] Trial 18 finished with value: 0.5747275010108318 and parameters: {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.013262845196171935}. Best is trial 16 with value: 0.5764763465344428.\n",
      "[I 2025-08-22 16:26:38,319] Trial 19 finished with value: 0.5595433168053457 and parameters: {'n_estimators': 100, 'max_depth': 7, 'learning_rate': 0.027698987238439977}. Best is trial 16 with value: 0.5764763465344428.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_params: {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.014777234896168582}\n",
      "best_value: 0.5765\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "def objective(trial):\n",
    "   \n",
    "    n_estimators = trial.suggest_int('n_estimators', 100, 300, step=20)\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 10)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0.01, 0.3, log=True)\n",
    "\n",
    "    scores = []\n",
    "\n",
    "    for train_idx, val_idx in skf.split(X, y):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "        scaler = MinMaxScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "       \n",
    "        model = xgb.XGBClassifier(\n",
    "            objective='binary:logistic',\n",
    "            eval_metric='logloss',\n",
    "            n_estimators=n_estimators,\n",
    "            max_depth=max_depth,\n",
    "            learning_rate=learning_rate,\n",
    "            n_jobs=-1,\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred = model.predict(X_val_scaled)\n",
    "        acc = accuracy_score(y_val, y_pred)\n",
    "        scores.append(acc)\n",
    "\n",
    "    return np.mean(scores)\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=20) \n",
    "\n",
    "\n",
    "print(\"best_params:\", study.best_params)\n",
    "print(f\"best_value: {study.best_value:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
