{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cefaaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "import optuna\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bc84752",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('cleaned.csv',index_col=0)\n",
    "testset=pd.read_csv('test.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48d30cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = df.drop('SMOKING', axis=1)\n",
    "y = df['SMOKING']\n",
    "\n",
    "X_test_new = testset.drop('SMOKING', axis=1)\n",
    "y_test_new = testset['SMOKING']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9610aa98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  \n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa872543",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 09:40:19,197] A new study created in memory with name: no-name-be618f9a-41ae-4c69-a775-a9168f9ebfdd\n",
      "[I 2025-08-16 09:40:19,805] Trial 0 finished with value: 0.777061224489796 and parameters: {'hidden1': 68, 'hidden2': 62, 'lr': 0.0029106359131330704, 'epochs': 44}. Best is trial 0 with value: 0.777061224489796.\n",
      "[I 2025-08-16 09:40:19,881] Trial 1 finished with value: 0.6233469387755102 and parameters: {'hidden1': 47, 'hidden2': 23, 'lr': 0.00013066739238053285, 'epochs': 55}. Best is trial 0 with value: 0.777061224489796.\n",
      "[I 2025-08-16 09:40:19,970] Trial 2 finished with value: 0.5178775510204082 and parameters: {'hidden1': 90, 'hidden2': 50, 'lr': 0.00010994335574766199, 'epochs': 59}. Best is trial 0 with value: 0.777061224489796.\n",
      "[I 2025-08-16 09:40:20,015] Trial 3 finished with value: 0.6150204081632653 and parameters: {'hidden1': 112, 'hidden2': 26, 'lr': 0.0002310201887845295, 'epochs': 27}. Best is trial 0 with value: 0.777061224489796.\n",
      "[I 2025-08-16 09:40:20,064] Trial 4 finished with value: 0.6679999999999999 and parameters: {'hidden1': 61, 'hidden2': 41, 'lr': 0.0007309539835912913, 'epochs': 31}. Best is trial 0 with value: 0.777061224489796.\n",
      "[I 2025-08-16 09:40:20,118] Trial 5 finished with value: 0.6964081632653061 and parameters: {'hidden1': 91, 'hidden2': 22, 'lr': 0.0003839629299804173, 'epochs': 35}. Best is trial 0 with value: 0.777061224489796.\n",
      "[I 2025-08-16 09:40:20,183] Trial 6 finished with value: 0.6316734693877551 and parameters: {'hidden1': 76, 'hidden2': 54, 'lr': 0.00025081156860452336, 'epochs': 41}. Best is trial 0 with value: 0.777061224489796.\n",
      "[I 2025-08-16 09:40:20,231] Trial 7 finished with value: 0.6637551020408162 and parameters: {'hidden1': 89, 'hidden2': 18, 'lr': 0.0016409286730647919, 'epochs': 26}. Best is trial 0 with value: 0.777061224489796.\n",
      "[I 2025-08-16 09:40:20,312] Trial 8 finished with value: 0.842204081632653 and parameters: {'hidden1': 38, 'hidden2': 62, 'lr': 0.00853618986286683, 'epochs': 53}. Best is trial 8 with value: 0.842204081632653.\n",
      "[I 2025-08-16 09:40:20,368] Trial 9 finished with value: 0.7284897959183674 and parameters: {'hidden1': 61, 'hidden2': 20, 'lr': 0.0023359635026261607, 'epochs': 38}. Best is trial 8 with value: 0.842204081632653.\n",
      "[I 2025-08-16 09:40:20,445] Trial 10 finished with value: 0.8217142857142857 and parameters: {'hidden1': 33, 'hidden2': 39, 'lr': 0.008691089486124973, 'epochs': 50}. Best is trial 8 with value: 0.842204081632653.\n",
      "[I 2025-08-16 09:40:20,519] Trial 11 finished with value: 0.8096326530612246 and parameters: {'hidden1': 33, 'hidden2': 35, 'lr': 0.009423326114108493, 'epochs': 51}. Best is trial 8 with value: 0.842204081632653.\n",
      "[I 2025-08-16 09:40:20,588] Trial 12 finished with value: 0.8337142857142856 and parameters: {'hidden1': 35, 'hidden2': 40, 'lr': 0.009799363313373048, 'epochs': 48}. Best is trial 8 with value: 0.842204081632653.\n",
      "[I 2025-08-16 09:40:20,663] Trial 13 finished with value: 0.8296326530612245 and parameters: {'hidden1': 49, 'hidden2': 64, 'lr': 0.005264621436623074, 'epochs': 47}. Best is trial 8 with value: 0.842204081632653.\n",
      "[I 2025-08-16 09:40:20,750] Trial 14 finished with value: 0.8216326530612246 and parameters: {'hidden1': 47, 'hidden2': 48, 'lr': 0.004629023753652255, 'epochs': 58}. Best is trial 8 with value: 0.842204081632653.\n",
      "[I 2025-08-16 09:40:20,838] Trial 15 finished with value: 0.7610612244897957 and parameters: {'hidden1': 120, 'hidden2': 31, 'lr': 0.0011118689234181692, 'epochs': 52}. Best is trial 8 with value: 0.842204081632653.\n",
      "[I 2025-08-16 09:40:20,912] Trial 16 finished with value: 0.813469387755102 and parameters: {'hidden1': 42, 'hidden2': 45, 'lr': 0.005143319656959443, 'epochs': 46}. Best is trial 8 with value: 0.842204081632653.\n",
      "[I 2025-08-16 09:40:20,997] Trial 17 finished with value: 0.8218775510204083 and parameters: {'hidden1': 58, 'hidden2': 56, 'lr': 0.009970682275036459, 'epochs': 54}. Best is trial 8 with value: 0.842204081632653.\n",
      "[I 2025-08-16 09:40:21,061] Trial 18 finished with value: 0.7328979591836735 and parameters: {'hidden1': 34, 'hidden2': 32, 'lr': 0.003785204179036118, 'epochs': 40}. Best is trial 8 with value: 0.842204081632653.\n",
      "[I 2025-08-16 09:40:21,162] Trial 19 finished with value: 0.753061224489796 and parameters: {'hidden1': 102, 'hidden2': 58, 'lr': 0.0007473544022951144, 'epochs': 60}. Best is trial 8 with value: 0.842204081632653.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_params: {'hidden1': 38, 'hidden2': 62, 'lr': 0.00853618986286683, 'epochs': 53}\n",
      "best_value: 0.8422\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "def objective(trial):\n",
    "    hidden1 = trial.suggest_int('hidden1', 32, 128)\n",
    "    hidden2 = trial.suggest_int('hidden2', 16, 64)\n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    epochs = trial.suggest_int('epochs', 20, 60)\n",
    "\n",
    "    scores = []\n",
    "\n",
    "    for train_idx, val_idx in skf.split(X, y):\n",
    "        \n",
    "        X_train_fold, X_val_fold = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train_fold, y_val_fold = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train_fold)\n",
    "        X_val_scaled = scaler.transform(X_val_fold)\n",
    "\n",
    "        \n",
    "        X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "        X_val_tensor = torch.tensor(X_val_scaled, dtype=torch.float32)\n",
    "        y_train_tensor = torch.tensor(y_train_fold.values, dtype=torch.float32).view(-1, 1)\n",
    "        y_val_tensor = torch.tensor(y_val_fold.values, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "        \n",
    "        class MLP(nn.Module):\n",
    "            def __init__(self, input_dim):\n",
    "                super().__init__()\n",
    "                self.model = nn.Sequential(\n",
    "                    nn.Linear(input_dim, hidden1),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(hidden1, hidden2),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(hidden2, 1),\n",
    "                    nn.Sigmoid()\n",
    "                )\n",
    "            def forward(self, x):\n",
    "                return self.model(x)\n",
    "        set_seed(42)\n",
    "        model = MLP(X_train_tensor.shape[1])\n",
    "        criterion = nn.BCELoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_train_tensor)\n",
    "            loss = criterion(outputs, y_train_tensor)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            y_pred = model(X_val_tensor)\n",
    "            y_pred_labels = (y_pred > 0.5).float()\n",
    "            acc = accuracy_score(y_val_tensor, y_pred_labels)\n",
    "            scores.append(acc)\n",
    "\n",
    "    return np.mean(scores)\n",
    "\n",
    "\n",
    "sampler = optuna.samplers.TPESampler(seed=42)\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "print(\"best_params:\", study.best_params)\n",
    "\n",
    "print(f\"best_value: {study.best_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69f4c450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train Accuracy: 1.0000\n",
      "\n",
      "test Accuracy: 0.8200\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8095    0.7727    0.7907        22\n",
      "         1.0     0.8276    0.8571    0.8421        28\n",
      "\n",
      "    accuracy                         0.8200        50\n",
      "   macro avg     0.8186    0.8149    0.8164        50\n",
      "weighted avg     0.8196    0.8200    0.8195        50\n",
      "\n",
      "\n",
      "train Accuracy: 0.9949\n",
      "\n",
      "test Accuracy: 0.8400\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8182    0.8182    0.8182        22\n",
      "         1.0     0.8571    0.8571    0.8571        28\n",
      "\n",
      "    accuracy                         0.8400        50\n",
      "   macro avg     0.8377    0.8377    0.8377        50\n",
      "weighted avg     0.8400    0.8400    0.8400        50\n",
      "\n",
      "\n",
      "train Accuracy: 0.9899\n",
      "\n",
      "test Accuracy: 0.8980\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8333    0.9524    0.8889        21\n",
      "         1.0     0.9600    0.8571    0.9057        28\n",
      "\n",
      "    accuracy                         0.8980        49\n",
      "   macro avg     0.8967    0.9048    0.8973        49\n",
      "weighted avg     0.9057    0.8980    0.8985        49\n",
      "\n",
      "\n",
      "train Accuracy: 0.9949\n",
      "\n",
      "test Accuracy: 0.8367\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7407    0.9524    0.8333        21\n",
      "         1.0     0.9545    0.7500    0.8400        28\n",
      "\n",
      "    accuracy                         0.8367        49\n",
      "   macro avg     0.8476    0.8512    0.8367        49\n",
      "weighted avg     0.8629    0.8367    0.8371        49\n",
      "\n",
      "\n",
      "train Accuracy: 0.9949\n",
      "\n",
      "test Accuracy: 0.8163\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8095    0.7727    0.7907        22\n",
      "         1.0     0.8214    0.8519    0.8364        27\n",
      "\n",
      "    accuracy                         0.8163        49\n",
      "   macro avg     0.8155    0.8123    0.8135        49\n",
      "weighted avg     0.8161    0.8163    0.8159        49\n",
      "\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "for train_idx, val_idx in skf.split(X, y):\n",
    "        \n",
    "        X_train_fold, X_val_fold = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train_fold, y_val_fold = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train_fold)\n",
    "        X_val_scaled = scaler.transform(X_val_fold)\n",
    "\n",
    "        \n",
    "        X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "        X_val_tensor = torch.tensor(X_val_scaled, dtype=torch.float32)\n",
    "        y_train_tensor = torch.tensor(y_train_fold.values, dtype=torch.float32).view(-1, 1)\n",
    "        y_val_tensor = torch.tensor(y_val_fold.values, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "        \n",
    "        class MLP(nn.Module):\n",
    "            def __init__(self, input_dim):\n",
    "                super().__init__()\n",
    "                self.model = nn.Sequential(\n",
    "                    nn.Linear(input_dim, 38), #48\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(38, 62), #35\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(62, 1),\n",
    "                    nn.Sigmoid()\n",
    "                )\n",
    "            def forward(self, x):\n",
    "                return self.model(x)\n",
    "        set_seed(42)\n",
    "        model = MLP(X_train_tensor.shape[1])\n",
    "        criterion = nn.BCELoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.00853618986286683) #0.005266579999771969\n",
    "        epochs=53\n",
    "        for epoch in range(epochs):\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_train_tensor)\n",
    "            loss = criterion(outputs, y_train_tensor)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            y_pred = model(X_val_tensor)\n",
    "            y_pred_labels = (y_pred > 0.5).float()\n",
    "            acc = accuracy_score(y_val_tensor, y_pred_labels)\n",
    "            \n",
    "\n",
    "            y_pred_train=model(X_train_tensor)\n",
    "            y_pred_labels_train = (y_pred_train > 0.5).float()\n",
    "            y_pred_labels_train_np = y_pred_labels_train.cpu().numpy()\n",
    "\n",
    "            train_acc=accuracy_score(y_train_fold, y_pred_labels_train)\n",
    "            \n",
    "            print(f\"\\ntrain Accuracy: {train_acc:.4f}\")\n",
    "            print(f\"\\ntest Accuracy: {acc:.4f}\")\n",
    "\n",
    "            print(\"\\nClassification Report:\\n\", classification_report(y_val_tensor, y_pred_labels, digits=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e4953f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train Accuracy: 0.9919\n",
      "\n",
      "test Accuracy: 0.8871\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8571    0.8889    0.8727        27\n",
      "         1.0     0.9118    0.8857    0.8986        35\n",
      "\n",
      "    accuracy                         0.8871        62\n",
      "   macro avg     0.8845    0.8873    0.8856        62\n",
      "weighted avg     0.8880    0.8871    0.8873        62\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X)\n",
    "X_test_scaled = scaler.transform(X_test_new)\n",
    "\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "X_val_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y.values, dtype=torch.float32).view(-1, 1)\n",
    "y_val_tensor = torch.tensor(y_test_new.values, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 38), #48\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(38, 62), #35\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(62, 1),\n",
    "                    nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "set_seed(42)\n",
    "model = MLP(X_train_tensor.shape[1])\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.00853618986286683) #0.005266579999771969\n",
    "\n",
    "epochs=53\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train_tensor)\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_val_tensor)\n",
    "    y_pred_labels = (y_pred > 0.5).float()\n",
    "    acc = accuracy_score(y_val_tensor, y_pred_labels)\n",
    "    \n",
    "\n",
    "    y_pred_train=model(X_train_tensor)\n",
    "    y_pred_labels_train = (y_pred_train > 0.5).float()\n",
    "    y_pred_labels_train_np = y_pred_labels_train.cpu().numpy()\n",
    "\n",
    "    train_acc=accuracy_score(y, y_pred_labels_train)\n",
    "    \n",
    "    print(f\"\\ntrain Accuracy: {train_acc:.4f}\")\n",
    "    print(f\"\\ntest Accuracy: {acc:.4f}\")\n",
    "\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_val_tensor, y_pred_labels, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed9c985c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_proba_mlp = model(X_val_tensor)   \n",
    "    y_proba_mlp_np = y_proba_mlp.cpu().numpy()      \n",
    "    y_proba_mlp_flat = y_proba_mlp_np.flatten()\n",
    "\n",
    "df_scores = pd.read_csv(\"roc_scores_rf.csv\")   \n",
    "\n",
    "df_scores[\"mlp\"] = y_proba_mlp_flat\n",
    "\n",
    "\n",
    "df_scores.to_csv(\"roc_scores_rf.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
