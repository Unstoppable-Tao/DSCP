{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "225ca310",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score,classification_report\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import optuna\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45159710",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('balanced_cleaned_train_dataset.csv')\n",
    "test_set=pd.read_csv('testset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f9b969c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop('smoking',axis=1)\n",
    "y=df['smoking']\n",
    "\n",
    "X_test_new= test_set.drop('smoking', axis=1)\n",
    "y_test_new = test_set['smoking']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03a84445",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  \n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ac88513",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-14 11:21:22,076] A new study created in memory with name: no-name-04046b15-ed03-413f-ab5a-ca13f10805b3\n",
      "[I 2025-08-14 11:21:23,394] Trial 0 finished with value: 0.8262499999999999 and parameters: {'hidden1': 68, 'hidden2': 62, 'lr': 0.0029106359131330704, 'epochs': 44}. Best is trial 0 with value: 0.8262499999999999.\n",
      "[I 2025-08-14 11:21:24,184] Trial 1 finished with value: 0.739 and parameters: {'hidden1': 47, 'hidden2': 23, 'lr': 0.00013066739238053285, 'epochs': 55}. Best is trial 0 with value: 0.8262499999999999.\n",
      "[I 2025-08-14 11:21:25,621] Trial 2 finished with value: 0.77815 and parameters: {'hidden1': 90, 'hidden2': 50, 'lr': 0.00010994335574766199, 'epochs': 59}. Best is trial 0 with value: 0.8262499999999999.\n",
      "[I 2025-08-14 11:21:26,253] Trial 3 finished with value: 0.79195 and parameters: {'hidden1': 112, 'hidden2': 26, 'lr': 0.0002310201887845295, 'epochs': 27}. Best is trial 0 with value: 0.8262499999999999.\n",
      "[I 2025-08-14 11:21:26,914] Trial 4 finished with value: 0.80465 and parameters: {'hidden1': 61, 'hidden2': 41, 'lr': 0.0007309539835912913, 'epochs': 31}. Best is trial 0 with value: 0.8262499999999999.\n",
      "[I 2025-08-14 11:21:27,781] Trial 5 finished with value: 0.8007 and parameters: {'hidden1': 91, 'hidden2': 22, 'lr': 0.0003839629299804173, 'epochs': 35}. Best is trial 0 with value: 0.8262499999999999.\n",
      "[I 2025-08-14 11:21:28,797] Trial 6 finished with value: 0.7325999999999999 and parameters: {'hidden1': 76, 'hidden2': 54, 'lr': 0.00025081156860452336, 'epochs': 41}. Best is trial 0 with value: 0.8262499999999999.\n",
      "[I 2025-08-14 11:21:29,441] Trial 7 finished with value: 0.8013 and parameters: {'hidden1': 89, 'hidden2': 18, 'lr': 0.0016409286730647919, 'epochs': 26}. Best is trial 0 with value: 0.8262499999999999.\n",
      "[I 2025-08-14 11:21:30,642] Trial 8 finished with value: 0.8272 and parameters: {'hidden1': 38, 'hidden2': 62, 'lr': 0.00853618986286683, 'epochs': 53}. Best is trial 8 with value: 0.8272.\n",
      "[I 2025-08-14 11:21:31,326] Trial 9 finished with value: 0.8192999999999999 and parameters: {'hidden1': 61, 'hidden2': 20, 'lr': 0.0023359635026261607, 'epochs': 38}. Best is trial 8 with value: 0.8272.\n",
      "[I 2025-08-14 11:21:32,178] Trial 10 finished with value: 0.8271000000000001 and parameters: {'hidden1': 33, 'hidden2': 39, 'lr': 0.008691089486124973, 'epochs': 50}. Best is trial 8 with value: 0.8272.\n",
      "[I 2025-08-14 11:21:33,041] Trial 11 finished with value: 0.8269 and parameters: {'hidden1': 33, 'hidden2': 35, 'lr': 0.009423326114108493, 'epochs': 51}. Best is trial 8 with value: 0.8272.\n",
      "[I 2025-08-14 11:21:33,848] Trial 12 finished with value: 0.8271499999999999 and parameters: {'hidden1': 35, 'hidden2': 40, 'lr': 0.009799363313373048, 'epochs': 48}. Best is trial 8 with value: 0.8272.\n",
      "[I 2025-08-14 11:21:34,928] Trial 13 finished with value: 0.8271000000000001 and parameters: {'hidden1': 49, 'hidden2': 64, 'lr': 0.005264621436623074, 'epochs': 47}. Best is trial 8 with value: 0.8272.\n",
      "[I 2025-08-14 11:21:36,030] Trial 14 finished with value: 0.8264500000000001 and parameters: {'hidden1': 47, 'hidden2': 48, 'lr': 0.004629023753652255, 'epochs': 58}. Best is trial 8 with value: 0.8272.\n",
      "[I 2025-08-14 11:21:37,458] Trial 15 finished with value: 0.82395 and parameters: {'hidden1': 120, 'hidden2': 31, 'lr': 0.0011118689234181692, 'epochs': 52}. Best is trial 8 with value: 0.8272.\n",
      "[I 2025-08-14 11:21:38,294] Trial 16 finished with value: 0.8262 and parameters: {'hidden1': 42, 'hidden2': 45, 'lr': 0.005143319656959443, 'epochs': 46}. Best is trial 8 with value: 0.8272.\n",
      "[I 2025-08-14 11:21:39,483] Trial 17 finished with value: 0.82775 and parameters: {'hidden1': 58, 'hidden2': 56, 'lr': 0.009970682275036459, 'epochs': 54}. Best is trial 17 with value: 0.82775.\n",
      "[I 2025-08-14 11:21:40,767] Trial 18 finished with value: 0.8276 and parameters: {'hidden1': 56, 'hidden2': 57, 'lr': 0.003813572755296343, 'epochs': 60}. Best is trial 17 with value: 0.82775.\n",
      "[I 2025-08-14 11:21:42,083] Trial 19 finished with value: 0.8269 and parameters: {'hidden1': 58, 'hidden2': 56, 'lr': 0.0029231239405734214, 'epochs': 60}. Best is trial 17 with value: 0.82775.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_params: {'hidden1': 58, 'hidden2': 56, 'lr': 0.009970682275036459, 'epochs': 54}\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "def objective(trial):\n",
    "    hidden1 = trial.suggest_int('hidden1', 32, 128)\n",
    "    hidden2 = trial.suggest_int('hidden2', 16, 64)\n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    epochs = trial.suggest_int('epochs', 20, 60)\n",
    "\n",
    "    scores = []\n",
    "\n",
    "    for train_idx, val_idx in skf.split(X, y):\n",
    "        \n",
    "        X_train_fold, X_val_fold = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train_fold, y_val_fold = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train_fold)\n",
    "        X_val_scaled = scaler.transform(X_val_fold)\n",
    "\n",
    "        \n",
    "        X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "        X_val_tensor = torch.tensor(X_val_scaled, dtype=torch.float32)\n",
    "        y_train_tensor = torch.tensor(y_train_fold.values, dtype=torch.float32).view(-1, 1)\n",
    "        y_val_tensor = torch.tensor(y_val_fold.values, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "        \n",
    "        class MLP(nn.Module):\n",
    "            def __init__(self, input_dim):\n",
    "                super().__init__()\n",
    "                self.model = nn.Sequential(\n",
    "                    nn.Linear(input_dim, hidden1),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(hidden1, hidden2),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(hidden2, 1),\n",
    "                    nn.Sigmoid()\n",
    "                )\n",
    "            def forward(self, x):\n",
    "                return self.model(x)\n",
    "        set_seed(42)\n",
    "        model = MLP(X_train_tensor.shape[1])\n",
    "        criterion = nn.BCELoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_train_tensor)\n",
    "            loss = criterion(outputs, y_train_tensor)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "       \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            y_pred = model(X_val_tensor)\n",
    "            y_pred_labels = (y_pred > 0.5).float()\n",
    "            acc = accuracy_score(y_val_tensor, y_pred_labels)\n",
    "\n",
    "\n",
    "          \n",
    "            y_pred_train = model(X_train_tensor)\n",
    "            y_pred_train_labels = (y_pred_train > 0.5).float()\n",
    "            acc_train = accuracy_score(y_train_tensor, y_pred_train_labels)\n",
    "        \n",
    "\n",
    "            overfit_penalty = abs(acc_train - acc)\n",
    "            score = 0.5 * acc - 0.5 * overfit_penalty\n",
    "            scores.append(acc)\n",
    "\n",
    "\n",
    "    return np.mean(scores)\n",
    "\n",
    "\n",
    "sampler = optuna.samplers.TPESampler(seed=42)\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "print(\"best_params:\", study.best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "523a939a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.6930\n",
      "Epoch 10, Loss: 0.4301\n",
      "Epoch 20, Loss: 0.4136\n",
      "Epoch 30, Loss: 0.4067\n",
      "Epoch 40, Loss: 0.4023\n",
      "Epoch 50, Loss: 0.3991\n",
      "\n",
      "train Accuracy: 0.8325\n",
      "\n",
      "Test Accuracy:  0.8325\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_test_new_scaler=scaler.transform(X_test_new)\n",
    "\n",
    "X_tensor = torch.tensor(X_scaled, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y.values, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "X_test_new_scaler_tensor=torch.tensor(X_test_new_scaler, dtype=torch.float32)\n",
    "y_test_new_tensor=torch.tensor(y_test_new.values, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(MLP, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 58),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(58, 56),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(56, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "set_seed(42)\n",
    "model = MLP(input_dim=X_tensor.shape[1])\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.009970682275036459)\n",
    "\n",
    "\n",
    "epochs = 54\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_tensor)\n",
    "    loss = criterion(outputs, y_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "\n",
    "    y_pred = model(X_test_new_scaler_tensor)\n",
    "    y_pred_labels = (y_pred > 0.5).float()\n",
    "\n",
    "    y_true = y_test_new_tensor.cpu().numpy()\n",
    "    y_pred_labels_np = y_pred_labels.cpu().numpy()\n",
    " \n",
    "    y_pred_train=model(X_tensor)\n",
    "    y_pred_labels_train = (y_pred_train > 0.5).float()\n",
    "\n",
    "    y_pred_labels_train_np = y_pred_labels_train.cpu().numpy()\n",
    "\n",
    "    train_acc=accuracy_score(y, y_pred_labels_train)\n",
    "    print(f\"\\ntrain Accuracy: {train_acc:.4f}\")\n",
    "    \n",
    "\n",
    "    acc = accuracy_score(y_true, y_pred_labels_np)\n",
    "    print(f\"\\nTest Accuracy:  {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2ff5604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Accuracy:  0.8325\n",
      "Test Precision: 0.7859\n",
      "Test Recall:    0.9140\n",
      "Test F1 Score:  0.8451\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8973    0.7510    0.8176      1000\n",
      "         1.0     0.7859    0.9140    0.8451      1000\n",
      "\n",
      "    accuracy                         0.8325      2000\n",
      "   macro avg     0.8416    0.8325    0.8314      2000\n",
      "weighted avg     0.8416    0.8325    0.8314      2000\n",
      "\n",
      "\n",
      "train Accuracy: 0.8325\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "\n",
    "    y_pred = model(X_test_new_scaler_tensor)\n",
    "    y_pred_labels = (y_pred > 0.5).float()\n",
    "\n",
    "    y_true = y_test_new_tensor.cpu().numpy()\n",
    "    y_pred_labels_np = y_pred_labels.cpu().numpy()\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    acc = accuracy_score(y_true, y_pred_labels_np)\n",
    "    precision = precision_score(y_true, y_pred_labels_np)\n",
    "    recall = recall_score(y_true, y_pred_labels_np)\n",
    "    f1 = f1_score(y_true, y_pred_labels_np)\n",
    "\n",
    "\n",
    "    print(f\"\\nTest Accuracy:  {acc:.4f}\")\n",
    "    print(f\"Test Precision: {precision:.4f}\")\n",
    "    print(f\"Test Recall:    {recall:.4f}\")\n",
    "    print(f\"Test F1 Score:  {f1:.4f}\")\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_true, y_pred_labels_np, digits=4))\n",
    "\n",
    "    \n",
    "    y_pred_train=model(X_tensor)\n",
    "    y_pred_labels_train = (y_pred_train > 0.5).float()\n",
    "    train_acc=accuracy_score(y, y_pred_labels_train)\n",
    "    print(f\"\\ntrain Accuracy: {train_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4dfeb77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train Accuracy: 0.8327\n",
      "\n",
      "test Accuracy: 0.8260\n",
      "------------------------------------------------------------\n",
      "\n",
      "train Accuracy: 0.8330\n",
      "\n",
      "test Accuracy: 0.8265\n",
      "------------------------------------------------------------\n",
      "\n",
      "train Accuracy: 0.8324\n",
      "\n",
      "test Accuracy: 0.8305\n",
      "------------------------------------------------------------\n",
      "\n",
      "train Accuracy: 0.8316\n",
      "\n",
      "test Accuracy: 0.8347\n",
      "------------------------------------------------------------\n",
      "\n",
      "train Accuracy: 0.8342\n",
      "\n",
      "test Accuracy: 0.8210\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for train_idx, val_idx in skf.split(X, y):\n",
    "    \n",
    "    X_train_fold, X_val_fold = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train_fold, y_val_fold = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train_fold)\n",
    "    X_val_scaled = scaler.transform(X_val_fold)\n",
    "\n",
    "    \n",
    "    X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "    X_val_tensor = torch.tensor(X_val_scaled, dtype=torch.float32)\n",
    "    y_train_tensor = torch.tensor(y_train_fold.values, dtype=torch.float32).view(-1, 1)\n",
    "    y_val_tensor = torch.tensor(y_val_fold.values, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "    \n",
    "    class MLP(nn.Module):\n",
    "        def __init__(self, input_dim):\n",
    "            super(MLP, self).__init__()\n",
    "            self.model = nn.Sequential(\n",
    "                nn.Linear(input_dim, 58),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(58, 56),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(56, 1),\n",
    "                nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        def forward(self, x):\n",
    "            return self.model(x)\n",
    "    set_seed(42)\n",
    "    model = MLP(X_train_tensor.shape[1])\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.009970682275036459)\n",
    "    epochs = 54\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train_tensor)\n",
    "        loss = criterion(outputs, y_train_tensor)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(X_val_tensor)\n",
    "        y_pred_labels = (y_pred > 0.5).float()\n",
    "        acc = accuracy_score(y_val_tensor, y_pred_labels)\n",
    "\n",
    "\n",
    "        \n",
    "        y_pred_train = model(X_train_tensor)\n",
    "        y_pred_train_labels = (y_pred_train > 0.5).float()\n",
    "        acc_train = accuracy_score(y_train_tensor, y_pred_train_labels)\n",
    "        print(f\"\\ntrain Accuracy: {acc_train:.4f}\")\n",
    "        print(f\"\\ntest Accuracy: {acc:.4f}\")\n",
    "        print(\"--\"*30)\n",
    "\n",
    "    \n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b17b5c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.figure(figsize=(8,5))\n",
    "# plt.plot(train_losses, label='Train Loss')\n",
    "# plt.plot(test_losses, label='Test Loss')\n",
    "# plt.xlabel(\"Epoch\")\n",
    "# plt.ylabel(\"Loss\")\n",
    "# plt.title(\"Train vs Test Loss Curve\")\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21579d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import KFold\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# import torch\n",
    "# import numpy as np\n",
    "\n",
    "# kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# fold_accuracies = []\n",
    "\n",
    "# for fold, (train_idx, test_idx) in enumerate(kfold.split(X_scaled)):\n",
    "#     print(f\"\\n=== Fold {fold + 1} ===\")\n",
    "\n",
    "    \n",
    "#     X_train, X_test = X_scaled[train_idx], X_scaled[test_idx]\n",
    "#     y_train, y_test = y.values[train_idx], y.values[test_idx]\n",
    "\n",
    "    \n",
    "#     X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "#     X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "#     y_train = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n",
    "#     y_test = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "    \n",
    "#     model = MLP(input_dim=X_train.shape[1])\n",
    "#     criterion = nn.BCELoss()\n",
    "#     optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    \n",
    "#     epochs = 300\n",
    "#     for epoch in range(epochs):\n",
    "#         model.train()\n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = model(X_train)\n",
    "#         loss = criterion(outputs, y_train)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "    \n",
    "#     model.eval()\n",
    "#     with torch.no_grad():\n",
    "#         y_pred = model(X_test)\n",
    "#         y_pred_labels = (y_pred > 0.5).float()\n",
    "#         acc = accuracy_score(y_test, y_pred_labels)\n",
    "#         print(f\"Fold {fold + 1} Accuracy: {acc:.4f}\")\n",
    "#         fold_accuracies.append(acc)\n",
    "\n",
    "\n",
    "# print(\"\\n=== Cross-Validation Summary ===\")\n",
    "# print(f\"All Accuracies: {fold_accuracies}\")\n",
    "# print(f\"Average Accuracy: {np.mean(fold_accuracies):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
